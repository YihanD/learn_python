{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Red Dragon Guide to Keras TPU MNIST - Run Live.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/YihanD/learn_python/blob/master/Red_Dragon_Guide_to_Keras_TPU_MNIST_Run_Live.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ON-UmcT_ZFqw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Red Dragon Guide to Keras for TPUs on Colabs\n",
        "\n",
        "Here is a very quick implemention and walkthrough to show using TPUs with Keras in Colabs\n",
        "\n",
        "if you have any questions or suggestions to make it better please let me know sam@reddragon.ai\n"
      ]
    },
    {
      "metadata": {
        "id": "dPamRBokUZEq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten,Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95qn1rJyHFz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dc76de34-446f-480d-d6ac-56c14bae36f8"
      },
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.11.0-rc2\n",
            "2.1.6-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zq4l11_Dtx8b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check for TPU\n",
        "\n",
        "To Test if you have GPU set up\n",
        "\n",
        "Run the Cell below\n",
        "\n",
        "if no TPU is found press Runtime (in the menu at the top) and choose \"Change Runtime Type\" to TPU\n",
        "\n",
        "The TPU_ADDRESS variable will be needed to pass into the distribution strategy."
      ]
    },
    {
      "metadata": {
        "id": "dwqHrONrZtng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54dc8c5d-a3aa-4eb0-aa7a-7bfb60883b21"
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    device_name = os.environ['COLAB_TPU_ADDR']\n",
        "    TPU_ADDRESS = 'grpc://' + device_name\n",
        "    print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "\n",
        "except KeyError:\n",
        "    print('TPU not found')\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found TPU at: grpc://10.91.6.42:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I6mOaxj3k30j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normal MNIST Stuff"
      ]
    },
    {
      "metadata": {
        "id": "181VT0eOUkL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LHmvV1heVGDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "891199b7-d0d2-4eda-c3b5-dd5a0e846433"
      },
      "cell_type": "code",
      "source": [
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1tidRmu9VM4E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vfinmHzDX6SH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2540c312-d641-4eb9-a0da-aef34462c6d4"
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HpOYyqEnX-G1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_K39jsGzJL-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use tf.data\n",
        "\n",
        "you need to make sure you have drop_remainder = True as TPUs need to have a fixed shape"
      ]
    },
    {
      "metadata": {
        "id": "abbwQQfH0td3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn(batch_size=1024):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.shuffle(1000).repeat().batch(batch_size, drop_remainder=True)\n",
        "\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVu91avJzMAO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_input_fn(batch_size=1024):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.shuffle(1000).repeat().batch(batch_size, drop_remainder=True)\n",
        "\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G_spUwX0VYGt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make the model\n",
        "\n",
        "you must pass in an input shape and batch size as TPUs (and XLA) require fixed shapes \n",
        "\n",
        "The rest of the model is just a simple CNN"
      ]
    },
    {
      "metadata": {
        "id": "qHzyhDMhVXHy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Inp = tf.keras.Input(\n",
        "      name='input', shape=input_shape, batch_size=batch_size, dtype=tf.float32)\n",
        "x = Conv2D(32, kernel_size=(3, 3), activation='relu',name = 'Conv_01')(Inp)\n",
        "x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_01')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu',name = 'Conv_02')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_02')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu',name = 'Conv_03')(x)\n",
        "x = Flatten(name = 'Flatten_01')(x)\n",
        "x = Dense(64, activation='relu',name = 'Dense_01')(x)\n",
        "x = Dropout(0.5,name = 'Dropout_02')(x)\n",
        "output = Dense(num_classes, activation='softmax',name = 'Dense_02')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xj-jMmGnuKX0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[Inp], outputs=[output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D00NKseRuOR3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use a tf optimizer rather than a Keras one for now\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "model.compile(\n",
        "      optimizer=opt,\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gEg_PWcIVa5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQnZM5JYlRvs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating the TPU from a Keras Model\n",
        "\n",
        "tf.contrib.tpu.keras_to_tpu_model will eventually go away and you will pass it into the model.compile as a distribution strategy, but for 1.11 this works. \n",
        "\n",
        "We can see this is a TPUv2 with 8 cores  \n",
        "\n",
        "For batching you want to have a batch of 128 per core so 1024 overall  \n",
        "\n",
        "You could also use 128,256, 512 etc "
      ]
    },
    {
      "metadata": {
        "id": "G-piuNdoWJGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "61c81f9b-e530-44db-b8f7-e5a02da50871"
      },
      "cell_type": "code",
      "source": [
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.91.6.42:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3681793728240691780)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9100542347921832641)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 6053035798767687467)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10503165079336209667)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17252578749855216314)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 5173933072814496408)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12245345672503976465)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1104787502455937549)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 18128471290821611624)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2962068197215635933)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 18438267734044374336)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2993021555126925334)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Connecting to: b'grpc://10.91.6.42:8470'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g2u9PUA9W7NK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "59a66afe-fef8-4d72-c5ee-1a2490c7d84d"
      },
      "cell_type": "code",
      "source": [
        "tpu_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (1024, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "Conv_01 (Conv2D)             (1024, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "MaxPool_01 (MaxPooling2D)    (1024, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv_02 (Conv2D)             (1024, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "MaxPool_02 (MaxPooling2D)    (1024, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "Conv_03 (Conv2D)             (1024, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "Flatten_01 (Flatten)         (1024, 576)               0         \n",
            "_________________________________________________________________\n",
            "Dense_01 (Dense)             (1024, 64)                36928     \n",
            "_________________________________________________________________\n",
            "Dropout_02 (Dropout)         (1024, 64)                0         \n",
            "_________________________________________________________________\n",
            "Dense_02 (Dense)             (1024, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_w2mss3nltod",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training using tf.data pipeline \n",
        "\n",
        "obviously training MNIST on a TPU is a bit overkill and the TPU barely gets a chance to warm up"
      ]
    },
    {
      "metadata": {
        "id": "x20Gu_lxXjOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "f12dae8d-5d81-4879-f7da-e368657318c0"
      },
      "cell_type": "code",
      "source": [
        "tpu_model.fit(\n",
        "    train_input_fn,\n",
        "    steps_per_epoch = 60,\n",
        "    epochs=10,\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train, [TensorSpec(shape=(1024, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(1024, 10), dtype=tf.float32, name=None)]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 1.7521159648895264 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "60/60 [==============================] - 6s 106ms/step - loss: 0.9943 - acc: 0.6882\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 3s 45ms/step - loss: 0.2443 - acc: 0.9276\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 3s 46ms/step - loss: 0.1506 - acc: 0.9560\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 3s 46ms/step - loss: 0.1155 - acc: 0.9675\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 3s 48ms/step - loss: 0.0929 - acc: 0.9741\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 3s 47ms/step - loss: 0.0752 - acc: 0.9785\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 3s 46ms/step - loss: 0.0648 - acc: 0.9819\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 4s 62ms/step - loss: 0.0562 - acc: 0.9847\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 3s 45ms/step - loss: 0.0479 - acc: 0.9859\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 3s 48ms/step - loss: 0.0474 - acc: 0.9858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BbC4yE3zYFhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e41280b-6268-4909-865e-e0f6275a61b0"
      },
      "cell_type": "code",
      "source": [
        "tpu_model.save_weights('./MNIST_TPU_1024.h5', overwrite=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KOMRVG_YYloD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "35feaa71-9ea1-40c9-a8ce-3bf9550a299a"
      },
      "cell_type": "code",
      "source": [
        "tpu_model.evaluate(test_input_fn,\n",
        "    steps = 100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval, [TensorSpec(shape=(1024, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(1024, 10), dtype=tf.float32, name=None)]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 1.035700798034668 secs\n",
            "100/100 [==============================] - 7s 69ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.026571716640610248, 0.991201171875]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "yfbDJQLK4LFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SlrmAjoH4LHm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hqMMMhPr4C0X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Doing it the exact same thing without tf.data is much slower"
      ]
    },
    {
      "metadata": {
        "id": "xxljvuMZNppb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ced72a45-04e3-4a7c-d59b-f9a4a4ca5bd8"
      },
      "cell_type": "code",
      "source": [
        "tpu_model.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=1\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train, [TensorSpec(shape=(4, 28, 28, 1), dtype=tf.float32, name='input0'), TensorSpec(shape=(4, 10), dtype=tf.float32, name='Dense_02_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 1.0727331638336182 secs\n",
            "60000/60000 [==============================] - 54s 905us/step - loss: 0.0909 - acc: 0.9739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tsivPBDL3Xmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}